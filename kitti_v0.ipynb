{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9YX7gGIb1nZb"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import cv2\n",
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = (20, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = r'2011_09_26/2011_09_26_drive_0106_sync'\n",
    "\n",
    "left_image_paths = sorted(glob(os.path.join(DATA_PATH, 'image_02/data/*.png')))\n",
    "right_image_paths = sorted(glob(os.path.join(DATA_PATH, 'image_03/data/*.png')))\n",
    "\n",
    "# get LiDAR data\n",
    "bin_paths = sorted(glob(os.path.join(DATA_PATH, 'velodyne_points/data/*.bin')))\n",
    "\n",
    "print(f\"Number of left images: {len(left_image_paths)}\")\n",
    "print(f\"Number of right images: {len(right_image_paths)}\")\n",
    "print(f\"Number of LiDAR point clouds: {len(bin_paths)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'2011_09_26/calib_cam_to_cam.txt','r') as f:\n",
    "    calib = f.readlines()\n",
    "\n",
    "# get projection matrices\n",
    "P_left = np.array([float(x) for x in calib[25].strip().split(' ')[1:]]).reshape((3,4))\n",
    "P_right = np.array([float(x) for x in calib[33].strip().split(' ')[1:]]).reshape((3,4))\n",
    "\n",
    "# get rectified rotation matrices\n",
    "R_left_rect = np.array([float(x) for x in calib[24].strip().split(' ')[1:]]).reshape((3, 3,))\n",
    "R_right_rect = np.array([float(x) for x in calib[32].strip().split(' ')[1:]]).reshape((3, 3,))\n",
    "\n",
    "R_left_rect = np.insert(R_left_rect, 3, values=[0,0,0], axis=0)\n",
    "R_left_rect = np.insert(R_left_rect, 3, values=[0,0,0,1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decompose_projection_matrix(P):    \n",
    "    K, R, T, _, _, _, _ = cv2.decomposeProjectionMatrix(P)\n",
    "    T = T/T[3]\n",
    "\n",
    "    return K, R, T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_left, R_left, T_left = decompose_projection_matrix(P_left)\n",
    "K_right, R_right, T_right = decompose_projection_matrix(P_right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'2011_09_26/calib_velo_to_cam.txt', 'r') as f:\n",
    "    calib = f.readlines()\n",
    "\n",
    "R_cam_velo = np.array([float(x) for x in calib[1].strip().split(' ')[1:]]).reshape((3, 3))\n",
    "t_cam_velo = np.array([float(x) for x in calib[2].strip().split(' ')[1:]])[:, None]\n",
    "\n",
    "T_cam_velo = np.vstack((np.hstack((R_cam_velo, t_cam_velo)),\n",
    "                        np.array([0, 0, 0, 1])))\n",
    "\n",
    "T_cam_velo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 10\n",
    "\n",
    "left_image = cv2.cvtColor(cv2.imread(left_image_paths[index]), cv2.COLOR_BGR2RGB)\n",
    "right_image = cv2.cvtColor(cv2.imread(right_image_paths[index]), cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The shape of an image is: {left_image.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, (ax1, ax2) = plt.subplots(1, 2, figsize=(25, 15))\n",
    "ax1.imshow(left_image)\n",
    "ax1.set_title('Left Image', size=22)\n",
    "ax2.imshow(right_image)\n",
    "ax2.set_title('Right Image', size=22);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_velo2cam(lidar_bin):\n",
    "    ''' Converts the LiDAR point cloud to camera (u, v, z) image coordinates, \n",
    "        where z is in meters\n",
    "        '''\n",
    "    # read in LiDAR data\n",
    "    scan_data = np.fromfile(lidar_bin, dtype=np.float32).reshape((-1,4))\n",
    "\n",
    "    # convert to homogeneous coordinate system\n",
    "    velo_points = scan_data[:, 0:3] # (x, y, z) --> (front, left, up)\n",
    "    velo_points = np.insert(velo_points, 3, 1, axis=1).T # homogeneous LiDAR points\n",
    "\n",
    "    # delete negative liDAR points\n",
    "    velo_points = np.delete(velo_points, np.where(velo_points[3, :] < 0), axis=1) \n",
    "\n",
    "    # possibly use RANSAC to remove the ground plane for better viewing?\n",
    "\n",
    "    # convert to camera coordinates\n",
    "    velo_camera = P_left @ R_left_rect @ T_cam_velo @ velo_points\n",
    "\n",
    "    # delete negative camera points ??\n",
    "    velo_camera  = np.delete(velo_camera , np.where(velo_camera [2,:] < 0)[0], axis=1) \n",
    "\n",
    "    # get camera coordinates u,v,z\n",
    "    velo_camera[:2] /= velo_camera[2, :]\n",
    "\n",
    "    return velo_camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_velo2cam(lidar_bin, image):\n",
    "    ''' Projects LiDAR point cloud onto the image coordinate frame '''\n",
    "\n",
    "    # get camera (u, v, z) coordinates\n",
    "    velo_camera = get_velo2cam(lidar_bin)\n",
    "\n",
    "    (u, v, z) = velo_camera\n",
    "\n",
    "    # remove outliers (points outside of the image frame)\n",
    "    img_h, img_w, _ = image.shape\n",
    "    u_out = np.logical_or(u < 0, u > img_w)\n",
    "    v_out = np.logical_or(v < 0, v > img_h)\n",
    "    outlier = np.logical_or(u_out, v_out)\n",
    "    velo_camera = np.delete(velo_camera, np.where(outlier), axis=1)\n",
    "    \n",
    "    return velo_camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lidar_bin = bin_paths[index]\n",
    "(u, v, z) = project_velo2cam(lidar_bin, left_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(left_image)\n",
    "plt.scatter([u], [v], c=[z], cmap='rainbow_r', alpha=0.5, s=2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sgbm_disparity(left_image, right_image, num_disparities=5*16, \n",
    "                           block_size=11, window_size=5, display=False):\n",
    "    \"\"\" Computes the disparity of an image pair using the SGBM algoithm.\n",
    "        Inputs: \n",
    "            image_left/_right - (MxN) grayscale input images\n",
    "            see opencv documentation for \"StereoBM_create\"\n",
    "        Outputs:\n",
    "            disparity (MxN) computed disparity map for the input images\n",
    "        \n",
    "        NOTE: image_left must be the left image (same for the right) or \n",
    "              unexpected results will occur due to \n",
    "    \"\"\"\n",
    "    # P1 and P2 control disparity smoothness (recommended values below)\n",
    "    P1 = 8 * 3 * window_size**2\n",
    "    P2 = 32 * 3 * window_size**2\n",
    "    sgbm_obj = cv2.StereoSGBM_create(0, num_disparities, block_size, \n",
    "        P1, P2, mode=cv2.STEREO_SGBM_MODE_SGBM_3WAY)\n",
    "        \n",
    "    # compute disparity\n",
    "    disparity = sgbm_obj.compute(left_image, right_image).astype(np.float32)/16.0\n",
    "\n",
    "    # display is desired\n",
    "    if display:\n",
    "      plt.figure(figsize = (40,20))\n",
    "      plt.imshow(disparity, cmap='cividis')\n",
    "      plt.title('Disparity Map', size=25)\n",
    "      plt.show();\n",
    "\n",
    "    return disparity\n",
    "\n",
    "def calc_depth_map(disp_left, K_left, T_left, T_right):\n",
    "    ''' Computes Depth map from Intrinsic Camera Matrix and Translations vectors.\n",
    "        For KITTI, the depth is in meters.\n",
    "        '''\n",
    "    # Get the focal length from the K matrix\n",
    "    f = K_left[0, 0]\n",
    "    \n",
    "    # Get the distance between the cameras from the t matrices (baseline)\n",
    "    b = np.abs(T_left[0] - T_right[0])[0]\n",
    "    \n",
    "    # Replace all instances of 0 and -1 disparity with a small minimum value (to avoid div by 0 or negatives)\n",
    "    disp_left[disp_left <= 0] = 1e-5\n",
    "    \n",
    "    # Calculate the depths \n",
    "    depth_map = f*b / disp_left \n",
    "\n",
    "    return depth_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_image_gray = cv2.cvtColor(left_image, cv2.COLOR_RGB2GRAY)\n",
    "right_image_gray = cv2.cvtColor(right_image, cv2.COLOR_RGB2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "from ipywidgets import interact, interactive, fixed\n",
    "\n",
    "disparity = interactive(compute_sgbm_disparity, \n",
    "                        left_image=fixed(left_image_gray), \n",
    "                        right_image=fixed(right_image_gray), \n",
    "                        num_disparities=(0,512,16), \n",
    "                        block_size=(1,19,2), \n",
    "                        window_size=(1,13,2),\n",
    "                        display=fixed(True))\n",
    "display(disparity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_disparities = disparity.kwargs['num_disparities']\n",
    "block_size = disparity.kwargs['block_size']\n",
    "window_size = disparity.kwargs['window_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disparity = compute_sgbm_disparity(left_image_gray, \n",
    "                                   right_image_gray, \n",
    "                                   num_disparities, \n",
    "                                   block_size, \n",
    "                                   window_size, \n",
    "                                   display=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(disparity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_map = calc_depth_map(disparity, K_left, T_left, T_right)\n",
    "plt.imshow(np.log(depth_map), cmap='rainbow_r'); # or 'cividis_r' or 'cividis'\n",
    "# plt.imshow(np.log(np.log(depth_map)), cmap='viridis_r');\n",
    "plt.scatter([u], [v], c=[z], cmap='rainbow_r', alpha=0.5, s=2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_map.shape\n",
    "u.shape\n",
    "v.shape\n",
    "z.shape\n",
    "\n",
    "def uvz_to_depth_map(uvz, image_shape):\n",
    "    depth_map = np.zeros(image_shape, dtype=np.float32)\n",
    "    \n",
    "    u, v, z = uvz\n",
    "    u, v = u.astype(np.int32), v.astype(np.int32)\n",
    "    \n",
    "    valid_indices = (u >= 0) & (u < image_shape[1]) & (v >= 0) & (v < image_shape[0])\n",
    "    u, v, z = u[valid_indices], v[valid_indices], z[valid_indices]\n",
    "    \n",
    "    depth_map[v, u] = z\n",
    "    \n",
    "    return depth_map\n",
    "    \n",
    "lidar_depth_map = uvz_to_depth_map((u, v, z), depth_map.shape)\n",
    "lidar_depth_map.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(lidar_depth_map, cmap='rainbow_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the depth map to Open3D depth image\n",
    "depth_image_o3d = o3d.geometry.Image(np.log(depth_map).astype(np.float32))\n",
    "\n",
    "# Create an Intrinsics object using camera parameters\n",
    "height, width = depth_map.shape\n",
    "fx, fy = K_left[0, 0], K_left[1, 1]\n",
    "cx, cy = K_left[0, 2], K_left[1, 2]\n",
    "intrinsic = o3d.camera.PinholeCameraIntrinsic(width, height, fx, fy, cx, cy)\n",
    "\n",
    "# Create a point cloud from the depth image\n",
    "point_cloud = o3d.geometry.PointCloud.create_from_depth_image(depth_image_o3d, intrinsic)\n",
    "\n",
    "# Visualize the point cloud\n",
    "o3d.visualization.draw_geometries([point_cloud])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def depth_map_to_point_cloud(depth_map, K):\n",
    "    \"\"\"\n",
    "    Convert a depth map into a 3D point cloud.\n",
    "\n",
    "    :param depth_map: The depth map to convert.\n",
    "    :param K: The intrinsic camera matrix.\n",
    "    :return: Open3D point cloud object.\n",
    "    \"\"\"\n",
    "    # Get the shape of the depth map\n",
    "    height, width = depth_map.shape\n",
    "\n",
    "    # Create a grid of coordinates corresponding to the depth map pixel indices\n",
    "    x, y = np.meshgrid(np.arange(width), np.arange(height))\n",
    "\n",
    "    # Normalize x and y to camera coordinates\n",
    "    x_normalized = (x - K[0, 2]) / K[0, 0]\n",
    "    y_normalized = (y - K[1, 2]) / K[1, 1]\n",
    "\n",
    "    # Create the point cloud in camera coordinates\n",
    "    points = np.stack((x_normalized * depth_map, y_normalized * depth_map, depth_map), axis=-1)\n",
    "\n",
    "    # Reshape to a list of 3D points\n",
    "    points = points.reshape(-1, 3)\n",
    "\n",
    "    # Remove points where the depth is zero\n",
    "    points = points[depth_map.flatten() > 0]\n",
    "\n",
    "    # Create an Open3D point cloud object\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(points)\n",
    "\n",
    "    return pcd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_rainbow_color(pcd):\n",
    "    \"\"\"\n",
    "    Apply a rainbow color map to a point cloud based on the z-coordinate.\n",
    "    \n",
    "    :param pcd: Open3D point cloud object.\n",
    "    :return: Colored Open3D point cloud object.\n",
    "    \"\"\"\n",
    "    # Convert Open3D point cloud to numpy array\n",
    "    points = np.asarray(pcd.points)\n",
    "\n",
    "    # Normalize z coordinates to the range [0, 1]\n",
    "    z = points[:, 2]\n",
    "    z_normalized = (z - np.min(z)) / (np.max(z) - np.min(z))\n",
    "\n",
    "    # Apply a colormap (rainbow)\n",
    "    colors = plt.cm.rainbow(z_normalized)[:, :3]\n",
    "\n",
    "    # Assign colors to point cloud\n",
    "    pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "    return pcd\n",
    "\n",
    "def calculate_point_colors_based_on_distance(point_cloud):\n",
    "    # Calculate distances from the origin (0, 0, 0)\n",
    "    distances = np.linalg.norm(point_cloud[:, :3], axis=1)\n",
    "\n",
    "    # Map distances to colors (rainbow colormap)\n",
    "    max_distance = np.max(distances)\n",
    "    colors = plt.get_cmap(\"rainbow\")(distances / max_distance)[:, :3]\n",
    "    return colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_lidar_data(bin_path):\n",
    "    # read in LiDAR data\n",
    "    scan_data = np.fromfile(lidar_bin, dtype=np.float32).reshape((-1,4))\n",
    "\n",
    "    # convert to homogeneous coordinate system\n",
    "    velo_points = scan_data[:, 0:3] # (x, y, z) --> (front, left, up)\n",
    "    \n",
    "    # delete negative liDAR points\n",
    "    velo_points = np.delete(velo_points, np.where(velo_points[3, :] < 0), axis=1) \n",
    "\n",
    "    # Convert to Open3D point cloud\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(velo_points) # Use only x, y, z for point cloud\n",
    "\n",
    "    return pcd\n",
    "\n",
    "lidar_pcd = read_lidar_data(lidar_bin)\n",
    "\n",
    "o3d.visualization.draw_geometries([lidar_pcd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lidar_pcd = read_lidar_data(lidar_bin)\n",
    "lidar_pcd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lidar_pcd = o3d.geometry.PointCloud()\n",
    "lidar_pcd.points = o3d.utility.Vector3dVector(get_velo2cam(lidar_bin)[:, :3])\n",
    "lidar_pcd\n",
    "\n",
    "# lidar_pcd.colors = o3d.utility.Vector3dVector(calculate_point_colors_based_on_distance(lidar_pcd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_pcd = depth_map_to_point_cloud(np.log(depth_map), K_left)\n",
    "depth_pcd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries([\n",
    "    lidar_pcd,\n",
    "    # apply_rainbow_color(depth_pcd)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vp = np.insert(np.fromfile(lidar_bin, dtype=np.float32).reshape((-1,4))[:,:3], 3, 1, axis=1).T\n",
    "# vp = np.delete(vp, np.where(vp[]))\n",
    "\n",
    "np.where(vp[3,:] < 0)\n",
    "\n",
    "# print(vp)\n",
    "# print(P_left)\n",
    "# print(R_left_rect)\n",
    "# print(T_cam_velo)\n",
    "\n",
    "vc = P_left @ R_left_rect @ T_cam_velo @ vp\n",
    "vc = np.delete(vc, np.where(vc[2,:] < 0)[0], axis=1)\n",
    "vc[:2] /= vc[2, :]\n",
    " \n",
    "# vc.shape\n",
    "# vc.T.shape\n",
    "\n",
    "# vf = vc.T\n",
    "\n",
    "# T_velo_cam = np.linalg.inv(R_left_rect @ T_cam_velo)\n",
    "# vf = T_velo_cam @ np.hstack((vf, np.ones((vf.shape[0], 1)))).T\n",
    "\n",
    "# vf.shape\n",
    "\n",
    "# vp = vf.T[:,:3]\n",
    "\n",
    "vp = vc.T\n",
    "vp.shape\n",
    "\n",
    "o3d.geometry.Poin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vpcd = o3d.geometry.PointCloud()\n",
    "vpcd.points = o3d.utility.Vector3dVector(vp)\n",
    "o3d.visualization.draw_geometries([vpcd])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('Python-ddiOOh4g')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "00f03ad223d9bbefba2d85a96e4c14bf4b7cfec3ac1501740897c115facd9986"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
