{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ayusufsirin/stereo_vision_starter/blob/main/kitti_v6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install GitPython open3d"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_KdwoculUwu",
        "outputId": "3dd4ace5-0bbe-4052-afc6-0d56933308ba"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: GitPython in /usr/local/lib/python3.10/dist-packages (3.1.42)\n",
            "Requirement already satisfied: open3d in /usr/local/lib/python3.10/dist-packages (0.18.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from GitPython) (4.0.11)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from open3d) (1.25.2)\n",
            "Requirement already satisfied: dash>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from open3d) (2.15.0)\n",
            "Requirement already satisfied: werkzeug>=2.2.3 in /usr/local/lib/python3.10/dist-packages (from open3d) (3.0.1)\n",
            "Requirement already satisfied: nbformat>=5.7.0 in /usr/local/lib/python3.10/dist-packages (from open3d) (5.9.2)\n",
            "Requirement already satisfied: configargparse in /usr/local/lib/python3.10/dist-packages (from open3d) (1.7)\n",
            "Requirement already satisfied: ipywidgets>=8.0.4 in /usr/local/lib/python3.10/dist-packages (from open3d) (8.1.2)\n",
            "Requirement already satisfied: addict in /usr/local/lib/python3.10/dist-packages (from open3d) (2.4.0)\n",
            "Requirement already satisfied: pillow>=9.3.0 in /usr/local/lib/python3.10/dist-packages (from open3d) (9.4.0)\n",
            "Requirement already satisfied: matplotlib>=3 in /usr/local/lib/python3.10/dist-packages (from open3d) (3.7.1)\n",
            "Requirement already satisfied: pandas>=1.0 in /usr/local/lib/python3.10/dist-packages (from open3d) (1.5.3)\n",
            "Requirement already satisfied: pyyaml>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from open3d) (6.0.1)\n",
            "Requirement already satisfied: scikit-learn>=0.21 in /usr/local/lib/python3.10/dist-packages (from open3d) (1.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from open3d) (4.66.2)\n",
            "Requirement already satisfied: pyquaternion in /usr/local/lib/python3.10/dist-packages (from open3d) (0.9.9)\n",
            "Requirement already satisfied: Flask<3.1,>=1.0.4 in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (2.2.5)\n",
            "Requirement already satisfied: plotly>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (5.15.0)\n",
            "Requirement already satisfied: dash-html-components==2.0.0 in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (2.0.0)\n",
            "Requirement already satisfied: dash-core-components==2.0.0 in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (2.0.0)\n",
            "Requirement already satisfied: dash-table==5.0.0 in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (5.0.0)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (4.9.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (2.31.0)\n",
            "Requirement already satisfied: retrying in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (1.3.4)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (1.6.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (67.7.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (7.0.1)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->GitPython) (5.0.1)\n",
            "Requirement already satisfied: comm>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.0.4->open3d) (0.2.1)\n",
            "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.0.4->open3d) (7.34.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.0.4->open3d) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=4.0.10 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.0.4->open3d) (4.0.10)\n",
            "Requirement already satisfied: jupyterlab-widgets~=3.0.10 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.0.4->open3d) (3.0.10)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->open3d) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->open3d) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->open3d) (4.48.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->open3d) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->open3d) (23.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->open3d) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->open3d) (2.8.2)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.7.0->open3d) (2.19.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.7.0->open3d) (4.19.2)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.7.0->open3d) (5.7.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0->open3d) (2023.4)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21->open3d) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21->open3d) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21->open3d) (3.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=2.2.3->open3d) (2.1.5)\n",
            "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from Flask<3.1,>=1.0.4->dash>=2.6.0->open3d) (3.1.3)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask<3.1,>=1.0.4->dash>=2.6.0->open3d) (2.1.2)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from Flask<3.1,>=1.0.4->dash>=2.6.0->open3d) (8.1.7)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.19.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (3.0.43)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (4.9.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (0.33.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (0.17.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly>=5.0.0->dash>=2.6.0->open3d) (8.2.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3->open3d) (1.16.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->dash>=2.6.0->open3d) (3.17.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core->nbformat>=5.7.0->open3d) (4.2.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->dash>=2.6.0->open3d) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->dash>=2.6.0->open3d) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->dash>=2.6.0->open3d) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->dash>=2.6.0->open3d) (2024.2.2)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.8.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.2.13)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "9YX7gGIb1nZb"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from glob import glob\n",
        "import cv2\n",
        "import open3d as o3d\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.rcParams[\"figure.figsize\"] = (20, 10)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone the git repo\n",
        "from git import Repo\n",
        "import os\n",
        "\n",
        "repo_url = 'https://github.com/ayusufsirin/stereo_vision_starter'\n",
        "local_dir = 'stereo_vision_starter'\n",
        "\n",
        "# Check if the directory exists and is a Git repository\n",
        "if os.path.isdir(local_dir) and os.path.isdir(os.path.join(local_dir, '.git')):\n",
        "    try:\n",
        "        repo = Repo(local_dir)\n",
        "        # Ensure the local repository is linked to the specified URL\n",
        "        if repo.remotes.origin.url == repo_url:\n",
        "            print(\"Repository already exists, pulling latest changes...\")\n",
        "            repo.remotes.origin.pull()\n",
        "        else:\n",
        "            print(\"Directory exists but is not linked to the specified repository URL.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "else:\n",
        "    try:\n",
        "        print(\"Cloning repository...\")\n",
        "        Repo.clone_from(repo_url, local_dir)\n",
        "        print(\"Repository cloned successfully.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while cloning the repository: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hHDLJtBJkfyd",
        "outputId": "10029608-6484-41aa-88c6-dcea7f740403"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Repository already exists, pulling latest changes...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nrjYj7swf74i",
        "outputId": "c2ecd544-8795-41cf-a82c-55f80b9dc04b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of left images: 1\n",
            "Number of right images: 1\n",
            "Number of LiDAR point clouds: 1\n",
            "Number of GT point clouds: 1\n"
          ]
        }
      ],
      "source": [
        "DATA_PATH = r'stereo_vision_starter/dataset/data_scene_flow/training/'\n",
        "RAW_DATA_PATH = r'stereo_vision_starter/dataset/2011_09_26/2011_09_26_drive_0057_sync'\n",
        "\n",
        "left_image_paths = sorted(glob(os.path.join(RAW_DATA_PATH, 'image_02/data/0000000125.png')))\n",
        "right_image_paths = sorted(glob(os.path.join(RAW_DATA_PATH, 'image_03/data/0000000125.png')))\n",
        "\n",
        "# get LiDAR data\n",
        "gt_paths = sorted(glob(os.path.join(DATA_PATH, 'disp_noc_0/000112_10.png')))\n",
        "\n",
        "lidar_paths = sorted(glob(os.path.join(RAW_DATA_PATH, 'velodyne_points/data/0000000125.bin')))\n",
        "\n",
        "print(f\"Number of left images: {len(left_image_paths)}\")\n",
        "print(f\"Number of right images: {len(right_image_paths)}\")\n",
        "print(f\"Number of LiDAR point clouds: {len(lidar_paths)}\")\n",
        "print(f\"Number of GT point clouds: {len(gt_paths)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "xfqzAnFWf74j",
        "outputId": "cf9b39a7-37d3-440f-c9cc-4a86e1439247"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "list index out of range",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-96e526c83275>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcalib_paths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'stereo_vision_starter/dataset/data_scene_flow_calib/training/calib_cam_to_cam/000112.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcalib_paths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mcalib\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ],
      "source": [
        "calib_paths = sorted(glob('stereo_vision_starter/dataset/data_scene_flow_calib/training/calib_cam_to_cam/000112.txt'))\n",
        "\n",
        "with open(calib_paths[0],'r') as f:\n",
        "    calib = f.readlines()\n",
        "\n",
        "# get projection matrices\n",
        "P_left = np.array([float(x) for x in calib[25].strip().split(' ')[1:]]).reshape((3,4))\n",
        "P_right = np.array([float(x) for x in calib[33].strip().split(' ')[1:]]).reshape((3,4))\n",
        "\n",
        "# get rectified rotation matrices\n",
        "R_left_rect = np.array([float(x) for x in calib[24].strip().split(' ')[1:]]).reshape((3, 3,))\n",
        "R_right_rect = np.array([float(x) for x in calib[32].strip().split(' ')[1:]]).reshape((3, 3,))\n",
        "\n",
        "R_left_rect = np.insert(R_left_rect, 3, values=[0,0,0], axis=0)\n",
        "R_left_rect = np.insert(R_left_rect, 3, values=[0,0,0,1], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "calib_paths\n",
        "!ls stereo_vision_starter/dataset/data_scene_flow_calib/training/calib_cam_to_cam/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDp5YT1CoW5X",
        "outputId": "49108734-c598-48aa-abbd-c7e1bcc6af8f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ls: cannot access 'stereo_vision_starter/dataset/data_scene_flow_calib/training/calib_cam_to_cam/': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C4HkMPiyf74j"
      },
      "outputs": [],
      "source": [
        "def decompose_projection_matrix(P):\n",
        "    K, R, T, _, _, _, _ = cv2.decomposeProjectionMatrix(P)\n",
        "    T = T/T[3]\n",
        "\n",
        "    return K, R, T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vvRyuNB1f74j"
      },
      "outputs": [],
      "source": [
        "K_left, R_left, T_left = decompose_projection_matrix(P_left)\n",
        "K_right, R_right, T_right = decompose_projection_matrix(P_right)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RQA3IJASf74j"
      },
      "outputs": [],
      "source": [
        "print(T_left)\n",
        "print(R_left)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZrwMrj-Xf74k"
      },
      "outputs": [],
      "source": [
        "calib_paths = sorted(glob('/media/joseph/Development/SFITC/kitti/data_scene_flow_calib/training/calib_velo_to_cam/*.txt'))\n",
        "\n",
        "with open(calib_paths[0], 'r') as f:\n",
        "    calib = f.readlines()\n",
        "\n",
        "R_cam_velo = np.array([float(x) for x in calib[1].strip().split(' ')[1:]]).reshape((3, 3))\n",
        "t_cam_velo = np.array([float(x) for x in calib[2].strip().split(' ')[1:]])[:, None]\n",
        "\n",
        "T_cam_velo = np.vstack((np.hstack((R_cam_velo, t_cam_velo)),\n",
        "                        np.array([0, 0, 0, 1])))\n",
        "\n",
        "T_cam_velo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QjmNi26Hf74k"
      },
      "outputs": [],
      "source": [
        "index = 0\n",
        "\n",
        "left_image = cv2.cvtColor(cv2.imread(left_image_paths[index]), cv2.COLOR_BGR2RGB)\n",
        "right_image = cv2.cvtColor(cv2.imread(right_image_paths[index]), cv2.COLOR_BGR2RGB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QemGaYuYf74k"
      },
      "outputs": [],
      "source": [
        "print(f\"The shape of an image is: {left_image.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L2P-L8opf74l"
      },
      "outputs": [],
      "source": [
        "_, (ax1, ax2) = plt.subplots(1, 2, figsize=(25, 15))\n",
        "ax1.imshow(left_image)\n",
        "ax1.set_title('Left Image', size=22)\n",
        "ax2.imshow(right_image)\n",
        "ax2.set_title('Right Image', size=22);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZOd-elEif74l"
      },
      "outputs": [],
      "source": [
        "def compute_sgbm_disparity(left_image, right_image, num_disparities=5*16,\n",
        "                           block_size=11, window_size=5, display=False):\n",
        "    \"\"\" Computes the disparity of an image pair using the SGBM algoithm.\n",
        "        Inputs:\n",
        "            image_left/_right - (MxN) grayscale input images\n",
        "            see opencv documentation for \"StereoBM_create\"\n",
        "        Outputs:\n",
        "            disparity (MxN) computed disparity map for the input images\n",
        "\n",
        "        NOTE: image_left must be the left image (same for the right) or\n",
        "              unexpected results will occur due to\n",
        "    \"\"\"\n",
        "    # P1 and P2 control disparity smoothness (recommended values below)\n",
        "    P1 = 8 * 3 * window_size**2\n",
        "    P2 = 32 * 3 * window_size**2\n",
        "    sgbm_obj = cv2.StereoSGBM_create(0, num_disparities, block_size,\n",
        "        P1, P2, mode=cv2.STEREO_SGBM_MODE_SGBM_3WAY)\n",
        "\n",
        "    # compute disparity\n",
        "    disparity = sgbm_obj.compute(left_image, right_image).astype(np.float32)/16.0\n",
        "\n",
        "    # display is desired\n",
        "    if display:\n",
        "      plt.figure(figsize = (40,20))\n",
        "      plt.imshow(disparity, cmap='cividis')\n",
        "      plt.title('Disparity Map', size=25)\n",
        "      plt.show();\n",
        "\n",
        "    return disparity\n",
        "\n",
        "def calc_depth_map(disp_left, K_left, T_left, T_right):\n",
        "    ''' Computes Depth map from Intrinsic Camera Matrix and Translations vectors.\n",
        "        For KITTI, the depth is in meters.\n",
        "        '''\n",
        "    # Get the focal length from the K matrix\n",
        "    f = K_left[0, 0]\n",
        "\n",
        "    # Get the distance between the cameras from the t matrices (baseline)\n",
        "    b = np.abs(T_left[0] - T_right[0])[0]\n",
        "\n",
        "    # Replace all instances of 0 and -1 disparity with a small minimum value (to avoid div by 0 or negatives)\n",
        "    disp_left[disp_left <= 0] = 1e-5\n",
        "\n",
        "    # Calculate the depths\n",
        "    depth_map = f*b / disp_left\n",
        "\n",
        "    return depth_map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yxkC9dSAf74l"
      },
      "outputs": [],
      "source": [
        "left_image_gray = cv2.cvtColor(left_image, cv2.COLOR_RGB2GRAY)\n",
        "right_image_gray = cv2.cvtColor(right_image, cv2.COLOR_RGB2GRAY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OgW-HjcOf74l"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Image\n",
        "from ipywidgets import interact, interactive, fixed\n",
        "\n",
        "disparity = interactive(compute_sgbm_disparity,\n",
        "                        left_image=fixed(left_image_gray),\n",
        "                        right_image=fixed(right_image_gray),\n",
        "                        num_disparities=(0,512,16),\n",
        "                        block_size=(1,19,2),\n",
        "                        window_size=(1,13,2),\n",
        "                        display=fixed(True))\n",
        "display(disparity)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1sWJqMDZf74m"
      },
      "outputs": [],
      "source": [
        "num_disparities = disparity.kwargs['num_disparities']\n",
        "block_size = disparity.kwargs['block_size']\n",
        "window_size = disparity.kwargs['window_size']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cvSXj2Kpf74m"
      },
      "outputs": [],
      "source": [
        "disparity = compute_sgbm_disparity(left_image_gray,\n",
        "                                   right_image_gray,\n",
        "                                   num_disparities,\n",
        "                                   block_size,\n",
        "                                   window_size,\n",
        "                                   display=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S3POZkc-f74m"
      },
      "outputs": [],
      "source": [
        "plt.imshow(disparity)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "guj5SZxtf74m"
      },
      "outputs": [],
      "source": [
        "gt = gt_paths[index]\n",
        "\n",
        "gt_disp = cv2.imread(gt, cv2.IMREAD_GRAYSCALE)\n",
        "# print(gt, type(gt_depth_map))\n",
        "\n",
        "gt_disp = gt_disp.astype(np.float32)\n",
        "# gt_disp[gt_disp == 0] = 1e-05\n",
        "\n",
        "gt_depth_map = calc_depth_map(gt_disp, K_left, T_left, T_right)\n",
        "gt_depth_map[gt_depth_map > 38000000.0] = np.NAN\n",
        "# gt_depth_map[gt_depth_map == 0] = np.NAN\n",
        "# gt_depth_map[gt_depth_map == np.Infinity] = np.NAN\n",
        "\n",
        "plt.imshow(gt_depth_map);\n",
        "gt_depth_map[50,600]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "igA8Ijoef74m"
      },
      "outputs": [],
      "source": [
        "def get_velo2cam(lidar_bin):\n",
        "    ''' Converts the LiDAR point cloud to camera (u, v, z) image coordinates,\n",
        "        where z is in meters\n",
        "        '''\n",
        "    # read in LiDAR data\n",
        "    scan_data = np.fromfile(lidar_bin, dtype=np.float32).reshape((-1,4))\n",
        "\n",
        "    # convert to homogeneous coordinate system\n",
        "    velo_points = scan_data[:, 0:3] # (x, y, z) --> (front, left, up)\n",
        "    velo_points = np.insert(velo_points, 3, 1, axis=1).T # homogeneous LiDAR points\n",
        "\n",
        "    # delete negative liDAR points\n",
        "    velo_points = np.delete(velo_points, np.where(velo_points[3, :] < 0), axis=1)\n",
        "\n",
        "    # possibly use RANSAC to remove the ground plane for better viewing?\n",
        "\n",
        "    # convert to camera coordinates\n",
        "    velo_camera = P_left @ R_left_rect @ T_cam_velo @ velo_points\n",
        "\n",
        "    # delete negative camera points ??\n",
        "    velo_camera  = np.delete(velo_camera , np.where(velo_camera [2,:] < 0)[0], axis=1)\n",
        "\n",
        "    # get camera coordinates u,v,z\n",
        "    velo_camera[:2] /= velo_camera[2, :]\n",
        "\n",
        "    return velo_camera\n",
        "\n",
        "def project_velo2cam(lidar_bin, image):\n",
        "    ''' Projects LiDAR point cloud onto the image coordinate frame '''\n",
        "\n",
        "    # get camera (u, v, z) coordinates\n",
        "    velo_camera = get_velo2cam(lidar_bin)\n",
        "\n",
        "    (u, v, z) = velo_camera\n",
        "\n",
        "    # remove outliers (points outside of the image frame)\n",
        "    img_h, img_w, _ = image.shape\n",
        "    u_out = np.logical_or(u < 0, u > img_w)\n",
        "    v_out = np.logical_or(v < 0, v > img_h)\n",
        "    outlier = np.logical_or(u_out, v_out)\n",
        "    velo_camera = np.delete(velo_camera, np.where(outlier), axis=1)\n",
        "\n",
        "    return velo_camera"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dqZerAcpf74m"
      },
      "outputs": [],
      "source": [
        "lidar_bin = lidar_paths[index]\n",
        "(u, v, z) = project_velo2cam(lidar_bin, left_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "59cviNNMf74m"
      },
      "outputs": [],
      "source": [
        "def uvz_to_depth_map(uvz, image_shape):\n",
        "    depth_map = np.zeros(image_shape, dtype=np.float32)\n",
        "\n",
        "    u, v, z = uvz\n",
        "    u, v = u.astype(np.int32), v.astype(np.int32)\n",
        "\n",
        "    valid_indices = (u >= 0) & (u < image_shape[1]) & (v >= 0) & (v < image_shape[0])\n",
        "    u, v, z = u[valid_indices], v[valid_indices], z[valid_indices]\n",
        "\n",
        "    depth_map[v, u] = z\n",
        "\n",
        "    return depth_map\n",
        "\n",
        "lidar_depth_map = uvz_to_depth_map((u, v, z), stereo_depth_map.shape)\n",
        "\n",
        "# TODO: Why not working?\n",
        "lidar_depth_map[lidar_depth_map == 0] = np.NAN\n",
        "\n",
        "plt.imshow(lidar_depth_map, cmap='rainbow_r');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HaoI_FW_f74n"
      },
      "outputs": [],
      "source": [
        "stereo_depth_map = calc_depth_map(disparity, K_left, T_left, T_right)\n",
        "stereo_depth_map[stereo_depth_map > 38000000.0] = np.NAN\n",
        "\n",
        "plt.imshow(stereo_depth_map, cmap='rainbow_r'); # or 'cividis_r' or 'cividis'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vs6IseM_f74n"
      },
      "source": [
        "## Overlapping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UpCeEtLUf74o"
      },
      "outputs": [],
      "source": [
        "lidar_depth_map.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KRV2UiSxf74o"
      },
      "outputs": [],
      "source": [
        "# TODO: Make this dynamic\n",
        "\n",
        "plt.imshow(lidar_depth_map[150:,:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "63YAUol8f74o"
      },
      "outputs": [],
      "source": [
        "plt.imshow(stereo_depth_map[:,80:])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IhNHe68Af74o"
      },
      "source": [
        "## Point Cloud"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W6XkQmP7f74o"
      },
      "outputs": [],
      "source": [
        "def depth_map_to_point_cloud(depth_map, flip=True):\n",
        "    # Convert the depth map to Open3D depth image\n",
        "    depth_image_o3d = o3d.geometry.Image(depth_map.astype(np.float32))\n",
        "\n",
        "    # Create an Intrinsics object using camera parameters\n",
        "    height, width = depth_map.shape\n",
        "    fx, fy = K_left[0, 0], K_left[1, 1]\n",
        "    cx, cy = K_left[0, 2], K_left[1, 2]\n",
        "    intrinsic = o3d.camera.PinholeCameraIntrinsic(\n",
        "        width, height, fx, fy, cx, cy)\n",
        "\n",
        "    # Create a point cloud from the depth image\n",
        "    point_cloud = o3d.geometry.PointCloud.create_from_depth_image(\n",
        "        depth_image_o3d,\n",
        "        intrinsic,\n",
        "        # depth_scale=1,\n",
        "        # depth_trunc=0.00070\n",
        "    )\n",
        "\n",
        "    if flip:\n",
        "        point_cloud.transform([\n",
        "            [1, 0, 0, 0],\n",
        "            [0, -1, 0, 0],\n",
        "            [0, 0, -1, 0],\n",
        "            [0, 0, 0, 1]\n",
        "        ])\n",
        "\n",
        "    return point_cloud\n",
        "\n",
        "\n",
        "def rgbd_to_point_cloud(color, depth_map, flip=True):\n",
        "    # Convert the depth map to Open3D depth image\n",
        "    depth_image_o3d = o3d.geometry.Image(depth_map.astype(np.float32))\n",
        "\n",
        "    # Convert the depth map to Open3D depth image\n",
        "    color_image_o3d = o3d.geometry.Image(color)\n",
        "\n",
        "    # Create RGBD image\n",
        "    rgbd_image_o3d = o3d.geometry.RGBDImage.create_from_color_and_depth(\n",
        "        color_image_o3d,\n",
        "        depth_image_o3d,\n",
        "        depth_scale=1,\n",
        "        depth_trunc=70\n",
        "        )\n",
        "\n",
        "    # Create an Intrinsics object using camera parameters\n",
        "    height, width = depth_map.shape\n",
        "    fx, fy = K_left[0, 0], K_left[1, 1]\n",
        "    cx, cy = K_left[0, 2], K_left[1, 2]\n",
        "    intrinsic = o3d.camera.PinholeCameraIntrinsic(\n",
        "        width, height, fx, fy, cx, cy)\n",
        "\n",
        "    # Create a point cloud from the depth image\n",
        "    point_cloud = o3d.geometry.PointCloud.create_from_rgbd_image(\n",
        "        rgbd_image_o3d, intrinsic)\n",
        "\n",
        "    if flip:\n",
        "        point_cloud.transform([\n",
        "            [1, 0, 0, 0],\n",
        "            [0, -1, 0, 0],\n",
        "            [0, 0, -1, 0],\n",
        "            [0, 0, 0, 1]\n",
        "        ])\n",
        "\n",
        "    return point_cloud\n",
        "\n",
        "# # Visualize the point cloud\n",
        "# o3d.visualization.draw_geometries([\n",
        "#     # depth_map_to_point_cloud(stereo_depth_map),\n",
        "#     depth_map_to_point_cloud(lidar_depth_map),\n",
        "#     rgbd_to_point_cloud(left_image, stereo_depth_map),\n",
        "# ])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qm8ndeJEf74p"
      },
      "source": [
        "## PG Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UrjT9IZdf74p"
      },
      "outputs": [],
      "source": [
        "import cupy as cp\n",
        "\n",
        "# vlp_depth = cp.array(lidar_depth_map)\n",
        "# zed_depth = cp.array(stereo_depth_map)\n",
        "# rgb = cp.array(left_image)\n",
        "gt_depth = cp.array(gt_depth_map[150:,80:])\n",
        "vlp_depth = cp.array(lidar_depth_map[150:,80:])\n",
        "zed_depth = cp.array(stereo_depth_map[150:,80:])\n",
        "rgb = cp.array(left_image[150:,80:])\n",
        "\n",
        "def fillB_withA(A, B):\n",
        "    # Combine A and B, prioritizing non-NaN values in A\n",
        "    combined = cp.where(cp.isnan(A), B, A)\n",
        "\n",
        "    # Calculate the column-wise means of the combined matrix, ignoring NaNs\n",
        "    col_means = cp.nanmean(combined, axis=0)\n",
        "\n",
        "    # Replace NaN values in the combined matrix with the column-wise means\n",
        "    combined = cp.where(cp.isnan(combined), col_means, combined)\n",
        "\n",
        "    return combined\n",
        "\n",
        "print(cp.count_nonzero(cp.isnan(vlp_depth)))\n",
        "print(cp.count_nonzero(cp.isnan(zed_depth)))\n",
        "\n",
        "mask = cp.isnan(zed_depth)\n",
        "\n",
        "zed_depth = cp.array(cv2.inpaint(zed_depth.get(), mask.get().astype(np.uint8), 3, cv2.INPAINT_TELEA))\n",
        "\n",
        "# zed_depth[cp.isnan(zed_depth)] = vlp_depth.mean()\n",
        "# zed_depth[cp.isnan(zed_depth)] = vlp_depth.max()\n",
        "# zed_depth[cp.isnan(zed_depth)] = vlp_depth.min()\n",
        "# zed_depth[zed_depth > 2000] = vlp_mean\n",
        "\n",
        "zed_depth = fillB_withA(vlp_depth, zed_depth)\n",
        "\n",
        "print(cp.count_nonzero(cp.isnan(zed_depth)))\n",
        "\n",
        "plt.imshow(np.log(zed_depth.get()), cmap='rainbow_r');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KCYt0-cYf74p"
      },
      "outputs": [],
      "source": [
        "def lpf(img, ncutoff):\n",
        "    # Apply 2D FFT to the image\n",
        "    f = cp.fft.fft2(img)\n",
        "\n",
        "    # Shift the zero frequency component to the center of the spectrum\n",
        "    fshift = cp.fft.fftshift(f)\n",
        "\n",
        "    # Create a circular mask of the same size as the spectrum\n",
        "    rows, cols = img.shape\n",
        "    crow, ccol = rows // 2, cols // 2\n",
        "    mask = np.zeros((rows, cols), np.uint8)\n",
        "    cutoff = int(min(crow, ccol)*ncutoff)\n",
        "    cv2.circle(mask, (ccol, crow), cutoff, 1, -1)\n",
        "    # cv2.ellipse(mask, (ccol, crow), (1, 2) * cutoff, 0, 0, 360,  1, -1)\n",
        "\n",
        "    mask = cp.asarray(mask)\n",
        "\n",
        "    # Apply the mask to the shifted spectrum\n",
        "    fshift_filtered = fshift * mask\n",
        "\n",
        "    # Shift the zero frequency component back to the corner of the spectrum\n",
        "    f_filtered = cp.fft.ifftshift(fshift_filtered)\n",
        "\n",
        "    # Apply the inverse 2D FFT to the filtered spectrum\n",
        "    img_filtered = cp.fft.ifft2(f_filtered)\n",
        "    img_filtered = cp.real(img_filtered)\n",
        "\n",
        "    return img_filtered\n",
        "\n",
        "\n",
        "def pg(zed_depth, vlp_depth, ncutoff, threshold=100):\n",
        "    mask = vlp_depth > 0\n",
        "    filtered = zed_depth\n",
        "\n",
        "    while threshold > 0:\n",
        "        filtered[mask] = vlp_depth[mask]\n",
        "        filtered = lpf(filtered, ncutoff)\n",
        "\n",
        "        threshold -= 1\n",
        "        # ncutoff = ncutoff / 10\n",
        "\n",
        "    return filtered\n",
        "\n",
        "\n",
        "pg_depth = pg(\n",
        "    cp.array(zed_depth.copy()),\n",
        "    cp.array(vlp_depth.copy()),\n",
        "    # cp.log(cp.array(zed_depth.copy())),\n",
        "    # cp.log(cp.array(vlp_depth.copy())),\n",
        "    ncutoff=10,\n",
        "    threshold=1000\n",
        ")\n",
        "\n",
        "# pg_depth = cp.exp(pg_depth)\n",
        "pg_depth[mask] = cp.NAN\n",
        "masked_zed_depth = zed_depth\n",
        "masked_zed_depth[mask] = cp.NAN\n",
        "\n",
        "# plt.imshow(pg_depth.get(), cmap='rainbow_r')\n",
        "# plt.imshow(np.log(pg_depth.get()), cmap='rainbow_r')\n",
        "# plt.imshow(np.exp(pg_depth.get()), cmap='rainbow_r')\n",
        "\n",
        "plt.subplot(3, 1, 1)\n",
        "plt.imshow(np.log(masked_zed_depth.get()), cmap='rainbow_r')\n",
        "plt.title('Zed')\n",
        "\n",
        "plt.subplot(3, 1, 2)\n",
        "plt.imshow(np.log(pg_depth.get()), cmap='rainbow_r')\n",
        "plt.title('PG')\n",
        "\n",
        "plt.subplot(3, 1, 3)\n",
        "plt.imshow(np.log(pg_depth.get() - zed_depth.get()), cmap='rainbow_r')\n",
        "plt.title('Diff')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xZy5w-yYf74p"
      },
      "outputs": [],
      "source": [
        "# Visualize the point cloud\n",
        "# o3d.visualization.draw_geometries([\n",
        "#     # depth_map_to_point_cloud(zed_depth.get()),\n",
        "#     rgbd_to_point_cloud(rgb.get(), masked_zed_depth.get()),\n",
        "#     # depth_map_to_point_cloud(vlp_depth.get()),\n",
        "#     # depth_map_to_point_cloud(gt_depth.get()),\n",
        "#     # rgbd_to_point_cloud(rgb.get(), pg_depth.get()),\n",
        "#     # depth_map_to_point_cloud(pg_depth.get()),\n",
        "# ])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ncs8ox-ff74p"
      },
      "source": [
        "## Benchmark\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "15WtStHcf74p"
      },
      "outputs": [],
      "source": [
        "def calculate_mae(predicted, ground_truth):\n",
        "    \"\"\"\n",
        "    Calculate the Mean Absolute Error (MAE) between predicted and ground truth images,\n",
        "    ignoring NaN values.\n",
        "\n",
        "    Parameters:\n",
        "    predicted (numpy.ndarray): Predicted depth image.\n",
        "    ground_truth (numpy.ndarray): Ground truth depth image.\n",
        "\n",
        "    Returns:\n",
        "    float: The MAE value.\n",
        "    \"\"\"\n",
        "    # Ensure the images have the same shape\n",
        "    if predicted.shape != ground_truth.shape:\n",
        "        raise ValueError(\"Predicted and ground truth images must have the same shape.\")\n",
        "\n",
        "    # Create a mask for valid (non-NaN) pixels\n",
        "    valid_mask = ~np.isnan(predicted) & ~np.isnan(ground_truth)\n",
        "\n",
        "    # Calculate the absolute differences only for valid pixels\n",
        "    diffs = np.abs(predicted[valid_mask] - ground_truth[valid_mask])\n",
        "\n",
        "    # Calculate the mean of these differences\n",
        "    mae = np.mean(diffs)\n",
        "    return mae\n",
        "\n",
        "print(calculate_mae(gt_depth.get(), gt_depth.get()))\n",
        "print(calculate_mae(pg_depth.get(), gt_depth.get()))\n",
        "print(calculate_mae(masked_zed_depth.get(), gt_depth.get()))\n",
        "print(calculate_mae(vlp_depth.get(), gt_depth.get()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bvlccWqvf74q"
      },
      "outputs": [],
      "source": [
        "def calculate_custom_mae(predicted, ground_truth):\n",
        "    \"\"\"\n",
        "    Calculate a custom Mean Absolute Error (MAE) between predicted and ground truth images.\n",
        "    NaN values in the ground truth are ignored. NaN values in the predicted image, where\n",
        "    the ground truth is not NaN, are penalized.\n",
        "\n",
        "    Parameters:\n",
        "    predicted (numpy.ndarray): Predicted depth image.\n",
        "    ground_truth (numpy.ndarray): Ground truth depth image.\n",
        "\n",
        "    Returns:\n",
        "    float: The custom MAE value.\n",
        "    \"\"\"\n",
        "    # Ensure the images have the same shape\n",
        "    if predicted.shape != ground_truth.shape:\n",
        "        raise ValueError(\"Predicted and ground truth images must have the same shape.\")\n",
        "\n",
        "    # Mask for valid pixels in ground truth\n",
        "    valid_gt_mask = ~np.isnan(ground_truth)\n",
        "\n",
        "    # Mask for pixels where predicted is NaN but ground truth is not\n",
        "    bad_pred_mask = np.isnan(predicted) & valid_gt_mask\n",
        "\n",
        "    # Assign a large error value for bad predictions\n",
        "    bad_pred_penalty = 1000  # or some other large number representing a high error\n",
        "\n",
        "    # Calculate absolute differences where both are valid and add penalty for bad predictions\n",
        "    diffs = np.abs(np.where(bad_pred_mask, bad_pred_penalty, predicted) - ground_truth)\n",
        "\n",
        "    # Calculate the mean over the ground truth valid mask\n",
        "    mae = np.mean(diffs[valid_gt_mask])\n",
        "    return mae\n",
        "\n",
        "print(calculate_custom_mae(gt_depth.get(), gt_depth.get()))\n",
        "print(calculate_custom_mae(pg_depth.get(), gt_depth.get()))\n",
        "print(calculate_custom_mae(masked_zed_depth.get(), gt_depth.get()))\n",
        "print(calculate_custom_mae(vlp_depth.get(), gt_depth.get()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MDM3vCwmf74q"
      },
      "outputs": [],
      "source": [
        "print(np.nan_to_num(pg_depth.get() - masked_zed_depth.get(), 0).max())\n",
        "print(np.nan_to_num(gt_depth.get() - masked_zed_depth.get(), 0).max())\n",
        "print(np.nan_to_num(vlp_depth.get() - masked_zed_depth.get(), 0).max())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HKoTqcw6f74q"
      },
      "outputs": [],
      "source": [
        "def calculate_rmse(predicted, ground_truth):\n",
        "    \"\"\"\n",
        "    Calculate the Root Mean Square Error (RMSE) between predicted and ground truth images,\n",
        "    taking into account NaN values.\n",
        "\n",
        "    Parameters:\n",
        "    predicted (numpy.ndarray): Predicted depth image.\n",
        "    ground_truth (numpy.ndarray): Ground truth depth image.\n",
        "\n",
        "    Returns:\n",
        "    float: The RMSE value.\n",
        "    \"\"\"\n",
        "    # Ensure the images have the same shape\n",
        "    if predicted.shape != ground_truth.shape:\n",
        "        raise ValueError(\"Predicted and ground truth images must have the same shape.\")\n",
        "\n",
        "    # Mask for valid pixels in ground truth\n",
        "    valid_gt_mask = ~np.isnan(ground_truth)\n",
        "\n",
        "    # Mask for pixels where predicted is NaN but ground truth is not\n",
        "    bad_pred_mask = np.isnan(predicted) & valid_gt_mask\n",
        "\n",
        "    # Assign a large error value for bad predictions\n",
        "    bad_pred_penalty = 1000  # or some other large number representing a high error\n",
        "\n",
        "    # Calculate squared differences where both are valid and add penalty for bad predictions\n",
        "    squared_diffs = (np.where(bad_pred_mask, bad_pred_penalty, predicted) - ground_truth) ** 2\n",
        "\n",
        "    # Calculate the mean of the squared differences over the ground truth valid mask and then take the square root\n",
        "    rmse = np.sqrt(np.mean(squared_diffs[valid_gt_mask]))\n",
        "    return rmse\n",
        "\n",
        "\n",
        "print(calculate_rmse(gt_depth.get(), gt_depth.get()))\n",
        "print(calculate_rmse(pg_depth.get(), gt_depth.get()))\n",
        "print(calculate_rmse(masked_zed_depth.get(), gt_depth.get()))\n",
        "print(calculate_rmse(vlp_depth.get(), gt_depth.get()))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.8.10 ('Python-ddiOOh4g')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "00f03ad223d9bbefba2d85a96e4c14bf4b7cfec3ac1501740897c115facd9986"
      }
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}